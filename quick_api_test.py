#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€ŸAPIæµ‹è¯•è„šæœ¬
ä½¿ç”¨ä»çœŸå®æ¸¸æˆè¿è¡Œä¸­ä¿å­˜çš„APIè¯·æ±‚å‚æ•°è¿›è¡Œæµ‹è¯•
"""

import time
import json
import os
from datetime import datetime
from api_test_config import *
from anthropic import Anthropic

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸  OpenAIæ¨¡å—æœªå®‰è£…ï¼Œå°†è·³è¿‡éClaudeæ¨¡å‹çš„æµ‹è¯•")

def get_api_client(model_name):
    """æ ¹æ®æ¨¡å‹åç§°è·å–å¯¹åº”çš„APIå®¢æˆ·ç«¯"""
    if model_name.startswith("claude"):
        return Anthropic(
            api_key=API_CONFIG["api_key"],
            base_url=API_CONFIG["base_url"]
        ), "anthropic"
    elif not OPENAI_AVAILABLE:
        raise Exception(f"æ¨¡å‹ {model_name} éœ€è¦OpenAIæ¨¡å—ï¼Œä½†æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install openai")
    elif model_name.startswith("gpt") or model_name.startswith("o1"):
        return openai.OpenAI(
            api_key=API_CONFIG.get("openai_api_key", API_CONFIG["api_key"]),
            base_url=API_CONFIG.get("openai_base_url", "https://api.openai.com/v1")
        ), "openai"
    elif model_name.startswith("gemini"):
        # å¯¹äºGeminiï¼Œæˆ‘ä»¬å‡è®¾ä½¿ç”¨OpenAIå…¼å®¹çš„æ¥å£
        return openai.OpenAI(
            api_key=API_CONFIG.get("gemini_api_key", API_CONFIG["api_key"]),
            base_url=API_CONFIG.get("gemini_base_url", API_CONFIG["base_url"])
        ), "openai"
    else:
        # é»˜è®¤ä½¿ç”¨OpenAIå…¼å®¹æ¥å£
        return openai.OpenAI(
            api_key=API_CONFIG["api_key"],
            base_url=API_CONFIG["base_url"]
        ), "openai"

def load_real_api_request():
    """åŠ è½½çœŸå®çš„APIè¯·æ±‚å‚æ•°"""
    real_request_file = "real_api_request.json"
    
    if not os.path.exists(real_request_file):
        print(f"âŒ æœªæ‰¾åˆ°çœŸå®APIè¯·æ±‚æ–‡ä»¶: {real_request_file}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œæ¸¸æˆä»£ç†è‡³å°‘ä¸€æ­¥ï¼Œä»¥ç”ŸæˆçœŸå®çš„APIè¯·æ±‚å‚æ•°")
        return None
    
    try:
        with open(real_request_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"âœ… å·²åŠ è½½çœŸå®APIè¯·æ±‚å‚æ•°")
        print(f"   ğŸ“… ç”Ÿæˆæ—¶é—´: {data.get('timestamp', 'æœªçŸ¥')}")
        print(f"   ğŸ¯ æ¸¸æˆæ­¥æ•°: {data.get('step_number', 'æœªçŸ¥')}")
        print(f"   ğŸ“ æ¶ˆæ¯æ•°é‡: {len(data.get('messages', []))}")
        
        return data
    except Exception as e:
        print(f"âŒ åŠ è½½çœŸå®APIè¯·æ±‚å‚æ•°å¤±è´¥: {e}")
        return None

def test_api_call_with_real_data(client, client_type, model_name, max_tokens, real_request_data):
    """ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡ŒAPIè°ƒç”¨æµ‹è¯•"""
    try:
        start_time = time.time()
        
        if client_type == "anthropic":
            # Anthropic APIè°ƒç”¨
            response = client.messages.create(
                model=model_name,
                max_tokens=max_tokens,
                system=real_request_data["system"],
                messages=real_request_data["messages"],
                tools=real_request_data["tools"],
                temperature=real_request_data["temperature"],
            )
            
            # æå–Anthropicå›ç­”å†…å®¹
            response_text = ""
            tool_calls = []
            
            for block in response.content:
                if block.type == "text":
                    response_text += block.text
                elif block.type == "tool_use":
                    tool_calls.append({
                        "name": block.name,
                        "input": block.input
                    })
            
            usage = response.usage
            
        else:
            # OpenAIå…¼å®¹APIè°ƒç”¨ï¼ˆåŒ…æ‹¬Geminiï¼‰
            try:
                # è½¬æ¢æ¶ˆæ¯æ ¼å¼
                openai_messages = []
                if real_request_data.get("system"):
                    openai_messages.append({"role": "system", "content": real_request_data["system"]})
                
                for msg in real_request_data["messages"]:
                    if msg["role"] == "user":
                        content = ""
                        if isinstance(msg["content"], list):
                            for item in msg["content"]:
                                if item["type"] == "text":
                                    content += item["text"] + "\n"
                                elif item["type"] == "image":
                                    content += "[å›¾ç‰‡å†…å®¹]\n"
                        else:
                            content = msg["content"]
                        openai_messages.append({"role": "user", "content": content})
                    else:
                        openai_messages.append(msg)
                
                # è½¬æ¢å·¥å…·æ ¼å¼
                openai_tools = []
                for tool in real_request_data.get("tools", []):
                    openai_tools.append({
                        "type": "function",
                        "function": {
                            "name": tool["name"],
                            "description": tool.get("description", ""),
                            "parameters": tool.get("input_schema", {})
                        }
                    })
                
                response = client.chat.completions.create(
                    model=model_name,
                    max_tokens=max_tokens,
                    messages=openai_messages,
                    tools=openai_tools if openai_tools else None,
                    temperature=real_request_data["temperature"],
                )
                
                # æå–OpenAIå›ç­”å†…å®¹
                response_text = response.choices[0].message.content or ""
                tool_calls = []
                
                if response.choices[0].message.tool_calls:
                    for tool_call in response.choices[0].message.tool_calls:
                        tool_calls.append({
                            "name": tool_call.function.name,
                            "input": json.loads(tool_call.function.arguments)
                        })
                
                usage = response.usage
                
            except Exception as openai_error:
                # å¦‚æœOpenAIæ ¼å¼å¤±è´¥ï¼Œå°è¯•ç®€åŒ–çš„è°ƒç”¨
                print(f"   âš ï¸  OpenAIæ ¼å¼è°ƒç”¨å¤±è´¥ï¼Œå°è¯•ç®€åŒ–è°ƒç”¨: {str(openai_error)[:100]}")
                
                # ç®€åŒ–çš„æ¶ˆæ¯æ ¼å¼
                simple_message = "è¯·åˆ†æå½“å‰æ¸¸æˆæˆªå›¾å¹¶é€‰æ‹©ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚"
                if real_request_data.get("messages"):
                    for msg in real_request_data["messages"]:
                        if msg["role"] == "user" and isinstance(msg["content"], list):
                            for item in msg["content"]:
                                if item["type"] == "text":
                                    simple_message = item["text"][:500]
                                    break
                            break
                
                response = client.chat.completions.create(
                    model=model_name,
                    max_tokens=max_tokens,
                    messages=[{"role": "user", "content": simple_message}],
                    temperature=0.7,
                )
                
                response_text = response.choices[0].message.content or ""
                tool_calls = []
                usage = response.usage
        
        duration = time.time() - start_time
        
        return {
            "success": True,
            "duration": duration,
            "usage": usage,
            "response_text": response_text,
            "tool_calls": tool_calls,
            "response_length": len(response_text),
            "error": None
        }
        
    except Exception as e:
        return {
            "success": False,
            "duration": 0,
            "usage": None,
            "response_text": "",
            "tool_calls": [],
            "response_length": 0,
            "error": str(e)
        }

def run_quick_comparison_with_real_data():
    """ä½¿ç”¨çœŸå®æ•°æ®è¿è¡Œå¿«é€Ÿå¯¹æ¯”æµ‹è¯•"""
    print("âš¡ åŸºäºçœŸå®æ¸¸æˆæ•°æ®çš„APIæ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    # åŠ è½½çœŸå®APIè¯·æ±‚æ•°æ®
    real_request_data = load_real_api_request()
    if not real_request_data:
        return []
    
    results = []
    
    for config in QUICK_TEST_CONFIGS:
        print(f"\nğŸ§ª æµ‹è¯• {config['name']}")
        print(f"   æ¨¡å‹: {config['model']}")
        print(f"   Max Tokens: {config['max_tokens']}")
        print(f"   è¯´æ˜: {config['description']}")
        print("   " + "-" * 40)
        
        # è·å–å¯¹åº”çš„APIå®¢æˆ·ç«¯
        try:
            client, client_type = get_api_client(config["model"])
        except Exception as e:
            print(f"   âŒ æ— æ³•åˆ›å»ºAPIå®¢æˆ·ç«¯: {e}")
            continue
        
        # æ‰§è¡Œæµ‹è¯•
        total_time = 0
        successful_tests = 0
        total_input_tokens = 0
        total_output_tokens = 0
        response_texts = []
        tool_calls_list = []
        
        for i in range(TEST_SETTINGS["test_rounds"]):
            print(f"   ç¬¬{i+1}è½®: ", end="")
            
            result = test_api_call_with_real_data(
                client, 
                client_type,
                config["model"], 
                config["max_tokens"], 
                real_request_data
            )
            
            if result["success"]:
                print(f"âœ… {result['duration']:.3f}ç§’", end="")
                if result["usage"]:
                    input_tokens = getattr(result["usage"], 'input_tokens', getattr(result["usage"], 'prompt_tokens', 0))
                    output_tokens = getattr(result["usage"], 'output_tokens', getattr(result["usage"], 'completion_tokens', 0))
                    print(f" (è¾“å…¥:{input_tokens}, è¾“å‡º:{output_tokens})")
                    total_input_tokens += input_tokens
                    total_output_tokens += output_tokens
                else:
                    print()
                
                # ä¿å­˜å›ç­”å†…å®¹ç”¨äºæ˜¾ç¤º
                response_texts.append(result["response_text"])
                tool_calls_list.append(result["tool_calls"])
                
                total_time += result['duration']
                successful_tests += 1
            else:
                print(f"âŒ å¤±è´¥: {result['error']}")
            
            time.sleep(TEST_SETTINGS["request_delay"])
        
        # æ˜¾ç¤ºæ¨¡å‹å›ç­”å†…å®¹
        if response_texts and successful_tests > 0:
            print(f"\n   ğŸ’­ æ¨¡å‹å›ç­”ç¤ºä¾‹:")
            sample_text = response_texts[0]
            if sample_text.strip():
                # æ˜¾ç¤ºå‰200å­—ç¬¦
                preview = sample_text[:200] + "..." if len(sample_text) > 200 else sample_text
                print(f"      {preview}")
            else:
                print(f"      [æ— æ–‡æœ¬å›ç­”]")
            
            if tool_calls_list and tool_calls_list[0]:
                print(f"   ğŸ”§ å·¥å…·è°ƒç”¨:")
                for tool_call in tool_calls_list[0]:
                    print(f"      - {tool_call['name']}: {tool_call['input']}")
            else:
                print(f"   ğŸ”§ å·¥å…·è°ƒç”¨: [æ— å·¥å…·è°ƒç”¨]")
        
        # è®¡ç®—å¹³å‡æ€§èƒ½
        if successful_tests > 0:
            avg_time = total_time / successful_tests
            avg_input_tokens = total_input_tokens / successful_tests if successful_tests > 0 else 0
            avg_output_tokens = total_output_tokens / successful_tests if successful_tests > 0 else 0
            
            # æ€§èƒ½è¯„çº§
            if avg_time <= PERFORMANCE_BENCHMARKS["excellent"]:
                grade = "ğŸ† ä¼˜ç§€"
            elif avg_time <= PERFORMANCE_BENCHMARKS["good"]:
                grade = "ğŸ¥ˆ è‰¯å¥½"
            elif avg_time <= PERFORMANCE_BENCHMARKS["acceptable"]:
                grade = "ğŸ¥‰ å¯æ¥å—"
            else:
                grade = "ğŸŒ è¾ƒæ…¢"
            
            print(f"   ğŸ“Š å¹³å‡è€—æ—¶: {avg_time:.3f}ç§’ {grade}")
            print(f"   ğŸ”¢ å¹³å‡Token: è¾“å…¥{avg_input_tokens:.0f}, è¾“å‡º{avg_output_tokens:.0f}")
            
            results.append({
                "name": config["name"],
                "model": config["model"],
                "max_tokens": config["max_tokens"],
                "avg_time": avg_time,
                "avg_input_tokens": avg_input_tokens,
                "avg_output_tokens": avg_output_tokens,
                "success_rate": successful_tests / TEST_SETTINGS["test_rounds"],
                "grade": grade
            })
        else:
            print(f"   âŒ æ‰€æœ‰æµ‹è¯•å¤±è´¥")
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š åŸºäºçœŸå®æ•°æ®çš„æ€§èƒ½å¯¹æ¯”ç»“æœ")
    print("=" * 60)
    
    if results:
        # æŒ‰æ€§èƒ½æ’åº
        results.sort(key=lambda x: x["avg_time"])
        
        print(f"\nğŸ† æ€§èƒ½æ’è¡Œ:")
        for i, result in enumerate(results, 1):
            efficiency = result["avg_output_tokens"] / result["avg_time"] if result["avg_time"] > 0 else 0
            print(f"{i}. {result['name']:<15} {result['avg_time']:6.3f}ç§’ {result['grade']} (æ•ˆç‡:{efficiency:.1f} tokens/s)")
        
        # æ¨èé…ç½®
        best = results[0]
        print(f"\nğŸ’¡ æœ€å¿«é…ç½®: {best['name']}")
        print(f"   æ¨¡å‹: {best['model']}")
        print(f"   Max Tokens: {best['max_tokens']}")
        print(f"   å¹³å‡è€—æ—¶: {best['avg_time']:.3f}ç§’")
        print(f"   Tokenæ•ˆç‡: {best['avg_output_tokens']/best['avg_time']:.1f} tokens/s")
        
        # æ˜¾ç¤ºçœŸå®æ•°æ®ç»Ÿè®¡
        print(f"\nğŸ“ˆ çœŸå®æ•°æ®ç»Ÿè®¡:")
        print(f"   åŸå§‹æ¨¡å‹: {real_request_data.get('model', 'æœªçŸ¥')}")
        print(f"   åŸå§‹Max Tokens: {real_request_data.get('max_tokens', 'æœªçŸ¥')}")
        print(f"   æ¶ˆæ¯å†å²é•¿åº¦: {len(real_request_data.get('messages', []))}")
        print(f"   å¯ç”¨å·¥å…·æ•°é‡: {len(real_request_data.get('tools', []))}")
        
        # è®¡ç®—æˆæœ¬æ•ˆç›Š
        print(f"\nğŸ’° æˆæœ¬æ•ˆç›Šåˆ†æ (åŸºäºå¹³å‡tokenä½¿ç”¨):")
        for result in results[:3]:  # åªæ˜¾ç¤ºå‰3å
            print(f"   {result['name']}: è¾“å…¥{result['avg_input_tokens']:.0f} + è¾“å‡º{result['avg_output_tokens']:.0f} tokens")
    
    return results

def test_single_model_with_real_data(model_name, max_tokens=1024, rounds=3):
    """ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•å•ä¸ªæ¨¡å‹"""
    print(f"ğŸ” åŸºäºçœŸå®æ•°æ®çš„å•æ¨¡å‹æµ‹è¯•: {model_name}")
    print(f"Max Tokens: {max_tokens}, æµ‹è¯•è½®æ•°: {rounds}")
    print("-" * 50)
    
    # åŠ è½½çœŸå®APIè¯·æ±‚æ•°æ®
    real_request_data = load_real_api_request()
    if not real_request_data:
        return None
    
    # è·å–å¯¹åº”çš„APIå®¢æˆ·ç«¯
    try:
        client, client_type = get_api_client(model_name)
    except Exception as e:
        print(f"âŒ æ— æ³•åˆ›å»ºAPIå®¢æˆ·ç«¯: {e}")
        return None
    
    times = []
    token_stats = []
    response_examples = []
    
    for i in range(rounds):
        print(f"ç¬¬{i+1}è½®: ", end="")
        
        result = test_api_call_with_real_data(client, client_type, model_name, max_tokens, real_request_data)
        
        if result["success"]:
            times.append(result["duration"])
            print(f"âœ… {result['duration']:.3f}ç§’", end="")
            
            if result["usage"]:
                input_tokens = getattr(result["usage"], 'input_tokens', getattr(result["usage"], 'prompt_tokens', 0))
                output_tokens = getattr(result["usage"], 'output_tokens', getattr(result["usage"], 'completion_tokens', 0))
                token_stats.append({
                    "input": input_tokens,
                    "output": output_tokens
                })
                print(f" (è¾“å…¥:{input_tokens}, è¾“å‡º:{output_tokens})")
            else:
                print()
            
            # ä¿å­˜å›ç­”å†…å®¹
            response_examples.append({
                "text": result['response_text'],
                "tool_calls": result['tool_calls']
            })
            
            # æ˜¾ç¤ºæ¨¡å‹å›ç­”å†…å®¹
            if TEST_SETTINGS.get("show_response_content", True):
                response_preview = result['response_text'][:300] + "..." if len(result['response_text']) > 300 else result['response_text']
                print(f"ğŸ’­ æ¨¡å‹å›ç­”: {response_preview}")
                if result['tool_calls']:
                    print(f"ğŸ”§ å·¥å…·è°ƒç”¨:")
                    for tool_call in result['tool_calls']:
                        print(f"   - {tool_call['name']}: {tool_call['input']}")
                print("-" * 50)
        else:
            print(f"âŒ å¤±è´¥: {result['error']}")
        
        if i < rounds - 1:  # æœ€åä¸€è½®ä¸éœ€è¦ç­‰å¾…
            time.sleep(TEST_SETTINGS["request_delay"])
    
    if times:
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        
        print(f"\nğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
        print(f"   å¹³å‡è€—æ—¶: {avg_time:.3f}ç§’")
        print(f"   æœ€å¿«: {min_time:.3f}ç§’")
        print(f"   æœ€æ…¢: {max_time:.3f}ç§’")
        print(f"   æˆåŠŸç‡: {len(times)}/{rounds} ({len(times)/rounds*100:.1f}%)")
        
        if token_stats:
            avg_input = sum(s["input"] for s in token_stats) / len(token_stats)
            avg_output = sum(s["output"] for s in token_stats) / len(token_stats)
            efficiency = avg_output / avg_time
            
            print(f"\nğŸ”¢ Tokenç»Ÿè®¡:")
            print(f"   å¹³å‡è¾“å…¥: {avg_input:.0f} tokens")
            print(f"   å¹³å‡è¾“å‡º: {avg_output:.0f} tokens")
            print(f"   ç”Ÿæˆæ•ˆç‡: {efficiency:.1f} tokens/s")
            
            # é¢„ä¼°æ¯å°æ—¶æ¸¸æˆæ­¥æ•°
            steps_per_hour = 3600 / avg_time
            print(f"\nğŸ® æ¸¸æˆæ€§èƒ½é¢„ä¼°:")
            print(f"   æ¯å°æ—¶å¯å®Œæˆ: {steps_per_hour:.0f} æ­¥")
            print(f"   æ¯åˆ†é’Ÿå¯å®Œæˆ: {steps_per_hour/60:.1f} æ­¥")
        
        return avg_time
    else:
        print("\nâŒ æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥äº†")
        return None

if __name__ == "__main__":
    print("ğŸ® åŸºäºçœŸå®æ¸¸æˆæ•°æ®çš„APIæ€§èƒ½æµ‹è¯•")
    print("=" * 40)
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨çœŸå®æ•°æ®æ–‡ä»¶
    if not os.path.exists("real_api_request.json"):
        print("âš ï¸  æœªæ‰¾åˆ°çœŸå®APIè¯·æ±‚æ•°æ®æ–‡ä»¶")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ç”ŸæˆçœŸå®æ•°æ®:")
        print("   python main.py --steps 1")
        print("\n   è¿™å°†è¿è¡Œæ¸¸æˆä¸€æ­¥å¹¶ä¿å­˜çœŸå®çš„APIè¯·æ±‚å‚æ•°")
        exit(1)
    
    print("é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. å¿«é€Ÿå¯¹æ¯”æµ‹è¯• (ä½¿ç”¨çœŸå®æ•°æ®)")
    print("2. å•æ¨¡å‹è¯¦ç»†æµ‹è¯• (ä½¿ç”¨çœŸå®æ•°æ®)")
    print("3. æ˜¾ç¤ºçœŸå®æ•°æ®ä¿¡æ¯")
    
    try:
        choice = input("\nè¯·é€‰æ‹© (1-3): ").strip()
        
        if choice == "1":
            results = run_quick_comparison_with_real_data()
            
        elif choice == "2":
            print("\nå¯ç”¨æ¨¡å‹:")
            for i, model in enumerate(MODELS_TO_TEST, 1):
                print(f"{i}. {model}")
            
            model_choice = input(f"\né€‰æ‹©æ¨¡å‹ (1-{len(MODELS_TO_TEST)}): ").strip()
            try:
                model_index = int(model_choice) - 1
                if 0 <= model_index < len(MODELS_TO_TEST):
                    model = MODELS_TO_TEST[model_index]
                    
                    # è¯¢é—®tokenæ•°é‡
                    tokens_input = input(f"Max tokens (é»˜è®¤1024): ").strip()
                    max_tokens = int(tokens_input) if tokens_input else 1024
                    
                    # è¯¢é—®æµ‹è¯•è½®æ•°
                    rounds_input = input(f"æµ‹è¯•è½®æ•° (é»˜è®¤3): ").strip()
                    rounds = int(rounds_input) if rounds_input else 3
                    
                    test_single_model_with_real_data(model, max_tokens, rounds)
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
                
        elif choice == "3":
            real_data = load_real_api_request()
            if real_data:
                print("\nğŸ“‹ çœŸå®APIè¯·æ±‚æ•°æ®ä¿¡æ¯:")
                print(f"   ğŸ¤– æ¨¡å‹: {real_data.get('model', 'æœªçŸ¥')}")
                print(f"   ğŸ”¢ Max Tokens: {real_data.get('max_tokens', 'æœªçŸ¥')}")
                print(f"   ğŸŒ¡ï¸  æ¸©åº¦: {real_data.get('temperature', 'æœªçŸ¥')}")
                print(f"   ğŸ“… ç”Ÿæˆæ—¶é—´: {real_data.get('timestamp', 'æœªçŸ¥')}")
                print(f"   ğŸ¯ æ¸¸æˆæ­¥æ•°: {real_data.get('step_number', 'æœªçŸ¥')}")
                print(f"   ğŸ’¬ æ¶ˆæ¯æ•°é‡: {len(real_data.get('messages', []))}")
                print(f"   ğŸ› ï¸  å·¥å…·æ•°é‡: {len(real_data.get('tools', []))}")
                
                # æ˜¾ç¤ºæ¶ˆæ¯ç»“æ„
                messages = real_data.get('messages', [])
                if messages:
                    print(f"\nğŸ“ æ¶ˆæ¯ç»“æ„:")
                    for i, msg in enumerate(messages):
                        role = msg.get('role', 'æœªçŸ¥')
                        content = msg.get('content', [])
                        if isinstance(content, list):
                            content_types = [item.get('type', 'æœªçŸ¥') for item in content]
                            print(f"   {i+1}. {role}: {', '.join(content_types)}")
                        else:
                            print(f"   {i+1}. {role}: æ–‡æœ¬")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ æµ‹è¯•è¢«ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
    
    print("\nğŸ æµ‹è¯•å®Œæˆ!")