#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
APIæµ‹è¯•é…ç½®æ–‡ä»¶
å¯ä»¥å¿«é€Ÿä¿®æ”¹æµ‹è¯•å‚æ•°è€Œä¸éœ€è¦ä¿®æ”¹ä¸»æµ‹è¯•æ–‡ä»¶
"""

# APIè¿æ¥é…ç½®
API_CONFIG = {
    "api_key": "sk-ksbCidPFhLiGTRo_I4fflYASF92UHYC8S1DNHp2kkbTaJkRShC8oOKPIJdI",
    "base_url": "https://chatapi.leyidc.net/claude",
}

# ============================================================================
# ğŸ¯ ç”¨æˆ·è‡ªå®šä¹‰æµ‹è¯•æ¨¡å‹åˆ—è¡¨ - åœ¨è¿™é‡Œä¿®æ”¹ä½ æƒ³æµ‹è¯•çš„æ¨¡å‹
# ============================================================================

# ä½ å¯ä»¥åœ¨è¿™é‡Œè¾“å…¥ä»»ä½•ä½ æƒ³æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨
USER_TEST_MODELS = [
    #"claude-3-7-sonnet-20250219",
    "claude-sonnet-4-20250514", 
    #"gemini-2.5-flash",
    #"gpt-4.1"
    # "claude-3-sonnet-20240229",
    # "claude-3-opus-20240229",
    
    # æ·»åŠ æ›´å¤šæ¨¡å‹åªéœ€è¦åœ¨è¿™é‡Œæ·»åŠ å³å¯ï¼Œä¾‹å¦‚ï¼š
    # "gpt-4-turbo",  # å¦‚æœä½ çš„APIæ”¯æŒå…¶ä»–æ¨¡å‹
]

# è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨ (ç”¨äºå•æ¨¡å‹æµ‹è¯•)
MODELS_TO_TEST = USER_TEST_MODELS

# æµ‹è¯•å‚æ•°
TEST_SETTINGS = {
    "test_rounds": 1,           # æ¯ä¸ªé…ç½®æµ‹è¯•å‡ è½®
    "request_delay": 1.0,       # è¯·æ±‚é—´éš”(ç§’)ï¼Œé¿å…é¢‘ç‡é™åˆ¶
    "timeout": 30,              # è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
    "temperature": 0.7,         # æ¨¡å‹æ¸©åº¦å‚æ•°
    "show_response_content": True,  # æ˜¾ç¤ºæ¨¡å‹å›ç­”å†…å®¹ç”¨äºè¯„ä¼°æ•ˆæœ
}

# æ€§èƒ½åŸºå‡† (ç”¨äºå¯¹æ¯”)
PERFORMANCE_BENCHMARKS = {
    "excellent": 2.0,    # 2ç§’ä»¥å†…ä¸ºä¼˜ç§€
    "good": 5.0,         # 5ç§’ä»¥å†…ä¸ºè‰¯å¥½  
    "acceptable": 10.0,  # 10ç§’ä»¥å†…ä¸ºå¯æ¥å—
    "poor": 15.0,        # 15ç§’ä»¥ä¸Šä¸ºè¾ƒå·®
}

def generate_quick_test_configs(models_list=None):
    """
    æ ¹æ®ç”¨æˆ·è¾“å…¥çš„æ¨¡å‹åˆ—è¡¨åŠ¨æ€ç”Ÿæˆæµ‹è¯•é…ç½®
    ä¸é¢„è®¾ä»»ä½•æ¨¡å‹æ€§èƒ½ç‰¹å¾ï¼Œå®Œå…¨åŸºäºç”¨æˆ·è¾“å…¥
    
    Args:
        models_list: è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨USER_TEST_MODELS
    
    Returns:
        list: ç”Ÿæˆçš„æµ‹è¯•é…ç½®åˆ—è¡¨
    """
    if models_list is None:
        models_list = USER_TEST_MODELS
    
    if not models_list:
        return []
    
    configs = []
    
    # ä¸ºæ¯ä¸ªæ¨¡å‹ç”ŸæˆåŸºç¡€é…ç½®
    for i, model in enumerate(models_list):
        # åŸºç¡€é…ç½® (1024 tokens)
        configs.append({
            "name": f"æ¨¡å‹{i+1}: {model}",
            "model": model,
            "max_tokens": 1024,
            "description": f"æµ‹è¯•æ¨¡å‹: {model}"
        })
        
        # é«˜tokené…ç½® (2048 tokens)
        configs.append({
            "name": f"æ¨¡å‹{i+1}+: {model} (é«˜token)",
            "model": model,
            "max_tokens": 4000,
            "description": f"æµ‹è¯•æ¨¡å‹: {model} - é«˜tokenç‰ˆæœ¬"
        })
    
    return configs

# åŠ¨æ€ç”Ÿæˆå¿«é€Ÿæµ‹è¯•é…ç½®
QUICK_TEST_CONFIGS = generate_quick_test_configs()

# æ‰“å°å½“å‰ç”Ÿæˆçš„é…ç½®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
if __name__ == "__main__":
    print("ğŸ¯ å½“å‰ç”¨æˆ·å®šä¹‰çš„æµ‹è¯•æ¨¡å‹:")
    for i, model in enumerate(USER_TEST_MODELS, 1):
        print(f"  {i}. {model}")
    
    print(f"\nğŸ“‹ ç”Ÿæˆçš„å¿«é€Ÿæµ‹è¯•é…ç½® ({len(QUICK_TEST_CONFIGS)}ä¸ª):")
    for config in QUICK_TEST_CONFIGS:
        print(f"  â€¢ {config['name']}: {config['model']} ({config['max_tokens']} tokens)")
        print(f"    {config['description']}")